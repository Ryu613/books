= 第三章 图形处理单元(GPU)

== 3.1 数据并行架构

不同的处理器架构使用各种策略来避免等待。CPU为处理大量数据和代码做优化。CPU可有多个处理器，但每次执行代码都几乎是串行的，有限的SIMD向量的执行是一个微小的例外。为了最小化延时的影响，很多CPU的芯片包含了高速本地缓存，来记录下一次执行需要的数据。CPU也通过使用一些巧妙的技术，比如分支预测，指令重排，寄存器重命名，缓存预取来避免等待。

GPU用了不同的方法。很多GPU的芯片区域被设计为一大组处理器，被称为着色器核心，一般来说有几千个。GPU是流式的处理器，一轮可以处理一组相似的数据。由于与处理一组顶点或像素的相似性，比如，GPU可以以大幅并行的方式处理这些数据。另一个重要的元素是，这些处理的调用过程是尽可能独立的，以便它们之间不需要额外的信息，同时不会共享可写入的内存区域。这些规则有时也会被打破，以便允许新的，或有用的功能，但是这些例外是以可能造成延时来作为成本的，因为一个处理器可能会等待另一个处理器完成它自己的工作。

.重点
****
* CPU擅长串行，GPU擅长并行，本质在于内核数量，GPU的核心就叫着色器核心
****

GPU是为吞吐量优化的，其是用数据处理的最大速率来定义的。然而这种高速处理是有成本的。由于留给缓存存储器和控制逻辑的芯片面积更小，每个着色器核心的延迟一般比CPU处理器的更高。

比如一个网格被光栅化，并且有2000个像素拥有片段(fragment)要被执行，某个像素着色器程序要被调用2000次，想象一下如果只有一个着色器处理器，堪称世界最弱GPU。这个GPU开始执行这个着色器程序的第一遍。这个着色器核心在寄存器上执行了少量算术操作。寄存器是本地的，且可高速访问，故没有等待发生。着色器核心之后收到指令，比如纹理的访问，即：对于给定的表面上的某个位置，程序需要知道这个网格的图像上这个像素点上的颜色。纹理是与网格完全分离的资源，并不是像素程序对应的本地存储器里的一部分，并且纹理的访问可能是会涉及到的。从内存里取到数据能耗费成百上千个时钟周期，这个时间内GPU处理器是闲置的，只是在等待纹理的颜色值返回

为了让这个糟糕的GPU变得更好，为每个片段提供了一小块存储空间给本地寄存器使用。现在，不会在纹理返回时等待，而是着色器处理器可以切换并执行另一个片段，即2000个片段中的第二个。这种切换是极致快的，不会影响第一和第二个片段，只会记录在第一个片段上执行了哪个指令。现在第二个片段被执行了。与第一个片段相同，一些算术操作被执行，然后又碰到纹理获取的操作。这个着色器核心现在切换到另一个片段，即第三个片段。最终所有2000个片段会用此种方式处理完毕。在这个时候，着色器核心返回到第一个片段。这回纹理的颜色已被返回，并且可被使用，故着色器程序可以被继续执行。处理器会以同样的方式执行，直到碰到另一个已知的需要等待的指令，或是程序已被执行完毕。如果着色器处理器只专注处理单个片段，执行的时间会更长，但是所有的片段的总体执行时间会大幅降低。

在这个架构下，GPU会忙于在片段的处理之间切换，延迟问题就被隐藏起来了。GPU采取并延伸了这种设计，把指令的执行逻辑与数据拆分开来。这被称为__单指令多数据(SIMD)__，这样的编排方式，对于固定数量的着色器程序，会以同时钟周期下同指令的方式执行相同的命令。相比为每个程序单独配备逻辑和调度单元，SIMD的优势在于：在数据处理和切换部分所需的硅面积和功耗都显著更低。把这个例子用现代GPU的术语来说就是，每个片元的像素着色器调用被称为线程。此类线程与CPU的线程不同，因其还包括了输入到这个着色器的值用到的内存和执行过程中用到的寄存器空间。使用同一个着色器程序的线程被打包成一组，NVIDIA称为__warps__, AMD称为__wavefronts__。一个 warp（或 wavefront）由若干个 GPU 着色器核心以 SIMD 方式调度执行，核心数量通常在 8 到 64 之间。每个线程对应一条 SIMD 通道（lane）

.重点
****
目标： GPU针对吞吐量优化，减少执行时间

手段： 着色器核心若遇到耗时操作，会在相同的执行过程中间切换，减少等待时间，即牺牲个体的执行时间，大幅提升总体执行时间

知识点：

. SIMD是一条指令同时处理多条数据，同一核心的时钟周期内，会执行同一条指令
. GPU的线程是：程序的调用+内存+寄存器空间，同一个着色器程序的线程看成一组，叫warp(NVIDIA)或wavefront(AMD)
. 一个warp/wavefront由8-64个核心执行，里面的每个线程有一条SIMD通道
****

假设现在我们有个2000个线程要被执行。NVIDIA的GPU利，每个warp包含32个线程。这会消耗2000/32=62.5warp, 也就是63个warp会被分配，有一个warp一半是空的。warp的执行与单GPU处理器类似。着色器程序会在32个处理器上同时钟周期内同指令执行

