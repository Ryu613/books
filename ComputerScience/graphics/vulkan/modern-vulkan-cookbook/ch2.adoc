= 现代Vulkan的使用

== 理解Vulkan的内存模型

内存分配和管理在vulkan中至关重要，因为Vulkan几乎不会管理内存的使用细节。除了决定要分配的确切内存地址外，其他的细节是由应用程序自己负责。这代表着程序员必须管理内存的类型，大小，和对齐，及其附属的分配操作。这种方式给予了app在内存管理方面更多的控制能力，并且允许开发者根据特定的用途来优化他们的程序。这份菜单会提供关于由API提供的内存类型的一些基本信息，也包括了一份关于如何分配和绑定这些内存到资源上的总结

[NOTE]
====
vulkan只负责决定内存地址的分配，app需自己负责内存管理，包括内存的类型，大小，对齐等
====

=== 准备

显卡里有两个变量: integrated(集成)和discrete(独立),集成显卡与CPU共享内存，如图2.1

image::img/fg2_1.png[图2.1]

独立显卡拥有自己的内存(即device内存)，与主内存(即host内存)是分开的，如图2.2

image::img/fg2_2.png[图2.2]

vulkan提供了不同的内存类型:

* Device-local内存: 此类型的内存针对GPU进行优化，属于device自己的，一般来说比host可见的内存要快，但是不能被CPU访问。一般来讲，类似渲染目标(render target), 图像存储, 和buffer都存到此处
* Host-visible内存: 此类型的内存可同时被GPU, CPU访问，一般来讲慢于device-local,但是允许数据在GPU和CPU之间高效传输，对于非集成GPU，从GPU读取到CPU的过程发生于PCI-E通道。一般来说，要先设置staging buffer,这里会存入将要传输给device-local内存里的数据，还有uniform buffer，这部分缓冲会在app中频繁更新
* Host-coherent内存: 此类内存类似host-visible内存，但是提供了GPU和CPU的内存一致性，比起上述两种内存类型更慢，但是对于要存储频繁在CPU和GPU中更新的数据来说很有用

[NOTE]
====
. Vulkan的三种内存类型:
.. device-local: 最快, device自己的内存，一般用来存render target, image, buffer, 不能被CPU直接访问
.. host-visible: 次快, CPU,GPU都可访问， 可用来做staging buffer和uniform buffer
.. host-coherent: 最慢, 可保证CPU/GPU的内存一致性
====

=== 如何做

创建和上传数据到buffer的一般步骤如下:

image::img/fgo_ch2_1.png[]

如你所见，这个过程比较繁琐，可用VMA库来简化实现，这是个开源库，为vulkan提供了便利且高效的内存管理方式，为内存的分配提供了高层接口，对复杂的细节进行的抽象，可让你从繁琐的手动内存管理中解脱出来。

== VMA库的初始化

为了使用VMA，首先，你需要创建这个库的实例，并且用VmaAllocator类型的句柄存下来。为了创建这个实例，需要vulkan的physical device和device

[NOTE]
====
也就是说: VMA是用来简化vulkan内存管理的，VMA实例的创建要在VkDevice创建完成后进行
====

=== 如何做

创建一个VMA库的实例需要实例化两个结构体:
* 指向Vulkan API函数的指针，VMA用来找到其他函数的指针
* vulkan的physical device, device, instance的句柄

[NOTE]
====
创建的代码片段参考原书或原书附带的代码(在github上)
====

这个分配器需要指向一些Vulkan函数的指针，以便其可根据你想要的特性来运行。在前例中，我们只提供了最小化的分配和释放内存的功能。分配器需要在context销毁时，使用vmaDestroyAllocator进行销毁

== buffer的创建

Vulkan中的buffer就是一个内存区块，里面有一些数据，这些数据可以是顶点，索引，uniform(全局数据)等等。buffer对象就是这个内存区快及其数据的抽象。与buffer关联的内存是在buffer创建后分配的

[NOTE]
====
buffer对象就是指一个内存区块及其里面的数据， 真正的内存分配是在buffer创建后才进行
====

[%header, cols=3*]
|===
|Buffer类型
|访问类型 
|用例

|Vertex/Index
|只读
|顶点或索引数据的存储

| Uniform
| 只读
| uniform数据的存储

| Storage
| 读/写
| 通用数据存储

| Uniform Texel(统一(全局)纹素)
| 读/写
| 数据被视作texel

| storage texel(存储纹素)
| 读/写
| 数据被视作texel
|===

buffer的创建很简单，但是上表有助于在创建和设置buffer时，了解buffer的类型和要求有哪些。在本章中，我们会提供一份buffer创建的模板代码

=== 准备

在代码中，Vulkan的buffer是用VulkanCore::Buffer类来管理的，此类提供了创建和上传数据给device的功能，还包括一个工具函数，此函数会是用staging buffer来把数据上传至设备独占的内存堆中

=== 如何做

用VMA创建buffer很简单：

. 创建VkBufferCreateInfo
. 创建VmaAllocationCreateFlagBits
. 调用vmaCreateBuffer
. 如果需要调试或优化，调用vmaGetAllocationInfo获取VmaAllocationInfo

== 把数据上传到buffer

把数据从app上传到GPU里的方式，是根据buffer的类型得来的。对于host-visible的buffer，可直接用memcpy来拷贝内存。对于device-local的buffer，我们需要一个暂存buffer(staging buffer), 这个buffer对于CPU和GPU来说都是可见的。在此菜单中，我们会演示如何从app传输到device-visible的内存中（这种buffer的内存区域在设备上）

=== 准备

如果你看不懂上文，请参考"理解Vulkan的内存模型"这一章节

=== 如何做

数据的上传方式取决于buffer的类型:

. 对于host-visible的内存，使用vmaMapMemory来获取目标内存的指针，然后用memcpy拷贝数据到其上即可。这个操作是同步的，所以已被map了的指针，只要memcpy返回后即可被unmap
当host-visible的buffer创建后立即map其上，除非销毁，否则不再改动这个已map的指针是被推荐的做法，这样做不会导致每次需要更新时，map操作的开销。
. 把数据上传到device-local的内存中，需要两步:
.. 先把数据拷贝到host可见的内存上(staging buffer)
.. 然后从staging buffer拷贝到device-local的内存上，是用vkCmdCopyBuffer,如下图所示，注意，这么做需要有一个command buffer
+
image::img/fg2_4.png[]
+
. 一旦数据移动到了device中的host-visible buffer(staging buffer), 就可用VkCmdCopyBuffer来把数据从staging buffer拷贝到device-local的内存上

[NOTE]
====
. 如果用host-visible的内存做buffer，那么直接调用vmaMapMemory把指针map到这块内存上，然后memcpy，unmap操作可以在销毁时再做，可减少buffer更新时，重复map/unmap的操作
. 对于device-local类型的内存做buffer,先把数据拷贝到staging buffer(host-visible)，再从staging buffer拷贝到device-local的内存
. 使用VMA时，buffer的分配和map/unmap调用改为使用vma开头的api，其他操作类似
====

== 创建一个staging buffer

创建staging buffer与创建一个普通的buffer类似，但是需要flags设定为host-visible,在此菜单中，我们会展示如何创建一个buffer，来作为staging buffer使用。 这种buffer可以被用作从app传输数据到device-local内存的中转

=== 准备

参考creating buffer这一章节

=== 如何做

VkBufferCreateInfo的usage需要包含VK_BUFFER_USAGE_TRANSFER_SRC_BIT, 因为他需要可以作为vkCmdCopyBuffer指令的数据源

staging buffer最好在你的app里进行封装实现。这个封装类可以对buffer的大小根据情况缩容或扩容。可能对于你的app只需要一个staging buffer就足够了。但是在某些系统架构上，内存的要求可能不一，需要注意。

== 如何使用ring buffer来避免数据竞争

当每一帧的buffer需要更新时，我们可能会遇到数据竞争的风险。如下图所示，数据竞争就是一种场景，在一个程序的多个线程并发访问共享的数据的时机，有至少一个线程正在执行写入的操作。这种并发访问，由于操作顺序的不确定，可导致不可预见的行为。比如，一个uniform buffer存储了view, model和视口的矩阵，并且需要在每一帧进行更新。buffer会在第一个指令缓冲记录时被更新并初始化成v1。一旦指令缓冲在GPU上开始处理，buffer包含了正确的数据：

image::img/fg2_5.png[]

在第一个在GPU上的指令缓冲开始执行后，app可能会在GPU访问的途中尝试更新buffer的内容，变成v2

[NOTE]
====
就是说，在CPU再往内存写数据时，GPU可能也正在读，有可能会出现GPU没有读到期望的数据，而是CPU后续写的数据(因为GPU真正执行的过程是异步的)
====






