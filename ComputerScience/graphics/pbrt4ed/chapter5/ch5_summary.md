# 第五章总结

图像要逼真，不仅要模拟相机镜片造成的畸变效果，还要模拟相机胶片和传感器的光辐射量测量，和成像过程。简单的小孔相机模型是不够的

pbrt中的相机，包括快门，镜片，胶片(及传感器，滤波器)的建模

类层次涉及及接口参考[chapter5.md](chapter5.md)

## 相机坐标空间

pbrt中主要是下列几种坐标系：

1. 物体空间: 物体自己的坐标系，比如:一个球体图元，为了方便，球心就可定在物体空间的坐标原点
2. 世界空间: 整个场景的坐标系，当物体放到场景中时，要从物体空间转成世界空间坐标
3. 相机空间: 相机放置于场景某点，原点是相机所在点，观察方向是z轴方向，相机"上"方向是y轴方向，坐标轴和原点随着相机进行旋转平移
4. 相机-世界空间: 原点是相机场景中的点，但是坐标轴与世界空间坐标方向一致，相机移动不会改变坐标轴方向，只会改变原点坐标
5. 渲染空间: 渲染时所基于的坐标空间，可以是世界空间，相机空间，或者相机-世界空间

传统上，大部分光栅化渲染器是基于相机空间来计算，pbrt-v4版本默认是在相机-世界空间计算和渲染，之前的版本默认是在世界空间渲染。切换到相机世界空间是为了解决当相机和物体离空间原点过远时，由于浮点数精度不够导致的图像撕裂问题，和包围盒在加速结构中计算效率降低的问题。

pbrt可以选具体用哪种渲染空间渲染，相机坐标的转换实现放到了CameraTransform类中

## 相机的类设计

pbrt里，相机有个主接口，叫Camera，有个基础类叫CameraBase,这个类派生了多个具体的相机类

具体的相机类，按投影方式，分为正交投影相机和透视投影相机，正交投影效果没有近大远小效果，透视投影类似人眼，有近大远小效果

正交和透视投影的具体实现要参考相关的构造器类，里面调用了Transform相关的方法，详见第三章

## 相机的可视范围

相机可以看到的视野是有限的，一方面是模拟现实情况，一方面也减轻计算机计算压力。

这里以透视投影为例:

在场景中，定义两个矩形面，分别代表场景中最近可看到的面和最远可看到的面，从相机所在点出发，按照相机-近平面左上角点-远平面左上角点，相机-近平面右上角点-远平面右上角点...以此类推形成了一个四棱锥，这个四棱锥的近平面和远平面截出来的中间部分，就是可视区域，在区域外的部分会在渲染时被裁切丢弃。

这个四棱锥也叫视锥体(Frustrum)

![图5.2](img/fg5_2.png)

如上图，近平面和远平面所基于的坐标系也分为3种:

1. 屏幕空间: 相机基于相机空间，把能看到的物体的坐标投影到胶片面后的坐标，注意z值是有意义的，在[0,1]之间，近平面上z=0,远平面上z=1，近平面就是胶片面，原点在图像平面的中心位置，左下角坐标为(-1,-1),右上角坐标为(1,1)
2. NDC空间: 被渲染的图像真正的坐标系，z值与屏幕空间中的值一样，但是x,y要变换到[0,1]之间,(0,0)是左上角，(1,1)是右下角
3. 光栅空间: x,y值是图像分辨率的像素数，其他跟NDC空间一致。

注意：屏幕空间中，(0,0)在中央, y轴朝上，NDC和光栅空间，(0,0)在左上角，y轴朝下(y方向是反的)

### 胶片

在pbrt的抽象里，像素是一个点，位于一个微小的矩形区域的中心，这个矩形代表了这个像素会对打到矩形内光产生响应，像素区域排列成更大的矩形区域，这个更大的区域就叫做胶片

像素点如何对光产生响应，响应多少，是由这个像素点的滤波函数f(x,y)决定,给出滤波函数的，就是滤波器(Filter)

感光元件(Sensor)会根据滤波器收集到的光辐射总量和波长，给出对应的颜色。在pbrt中，主要模拟三种效果:

1. 曝光控制：即图像明暗程度
2. RGB相应: 基于光谱响应曲线，把光辐射量转为RGB颜色
3. 白平衡: 模拟人类视觉系统中的色彩从暗到亮的适应过程
